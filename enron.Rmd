---
title: "Midterm Project - Madison Lindsay"
date: "03/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE)
```

This project involves natural language processing and you will practice your R skills including for loops, data visualization, string manipulation and maybe some network modeling. The final submission should include: (1) A report with sections such as introduction,  methodology and result. You are encouraged to use **latex** to write the report. However, a word document or pdf generated using Rmarkdown is acceptable. (2) Your R script for data analysis. Note that if you choose to use Rmarkdown, please try to put most of your functions and data cleaning script to a folder called `R` and present minimal amount of coding in the Rmarkdown file. A suggestion is to create the following directories inside your project `data/`, `R/` and `figures/` to organize your files. 

This project is due on 03/21/2021 and we will cancel our class on 03/18/2021 to give you more time to work on the project. 

## Introduction

This dataset is named Enron Corpus, which was collected and prepared by the CALO Project (Cognitive Assistant that Learns and Organizes). It contains data from about 150 users, mostly senior management of Enron, organized into folders. The corpus contains a total of about 0.5M messages. This data was originally made public, and posted to the web, by the Federal Energy Regulatory Commission during its investigation.

The email dataset was later purchased by Leslie Kaelbling at MIT, and turned out to have a number of integrity problems. A number of folks at SRI, notably Melinda Gervasio, worked hard to correct these problems, and it is thanks to them that the dataset is available. The dataset here does not include attachments, and some messages have been deleted "as part of a redaction effort due to requests from affected employees." Invalid email addresses were converted to something of the form user@enron.com whenever possible (i.e., recipient is specified in some parse-able format like "Doe, John" or "Mary K. Smith") and to no_address@enron.com when no recipient was specified.

This dataset, along with a thorough
explanation of its origin, is available at http://www-2.cs.cmu.edu/~enron/. I have downloaded it and put it into the project's dropbox folder. In the folder, there is a R script (`starting_code.R`) giving you some examples how to handle the data - reading, extracting information and so on. 

This project is then aiming at analyzing this big real email data set. Below I list some problems to explore. Feel free to add more analyses that are interesting to you. 


Midterm project problems
===
1. As you can see that my code is just for demonstrating purpose, and it is not well functioning because: 1.  the email names I extracted are contaminated, e.g., some names are "houston <.ward@", and "pr <.palmer@"; 2. there are multiple folders for each person. Try to improve my code. At the very beginning, you want to do data exploration: how many unique users/email addresses we have in this email and how many of them belong to the company. 

```{r}
rm(list=ls())
library("reader")
library("plyr")
library("ggplot2")
library("viridis")
library("tidyverse")
library("patchwork")
library("igraph")
library("xtable")
library("uuid")
data_location = "/Users/madisonlindsay/school/2021_spring/893/MidtermProject/data/"

source("R/functions.R")
df <- load_data(from_csv=TRUE)  # CSV was generated by running the two lines below
# df_new <- load_data(data_location = data_location)
# write.csv(df_new,"lots_of_emails.csv", row.names=FALSE)
```

```{r}
setwd(data_location)
emails.all.files <- list.files("maildir/", full.names = T, recursive = T)
# number of unique users
length(unique(str_match(emails.all.files,"maildir//(.*?)/.*")[,2]))
# number of unique email addresses
froms = apply(as.data.frame(paste0(data_location,emails.all.files)), 1, 
              function(x){readLines(x, warn = F)[3]})
length(unique(froms))
# number of unique Enron email addresses
length(unique(froms)[grepl("@enron.com", unique(froms))])

#Message ID is a row ID
length(unique(df$message_id)) == nrow(df)
```

2. Plot a figure to show the total number of emails sending and receiving by each employee in this company. Hint: Plot two figures, one for sending and one for receiving.  Rank the total numbers increasingly and show top 10 people who got the most emails and who sent the most emails. Try to do a little reading of this public dataset and maybe figure out their roles in the company. 

```{r}
# Top 10 Email Senders:
senders = tapply(df$message_id, INDEX = df$from,FUN=function(x) length(unique(x)))
xtable(as.data.frame(sort(senders, decreasing=TRUE)[1:10]))
# Top 10 Email Recipients:
recipients = tapply(df$message_id, INDEX = df$to,FUN=function(x) length(unique(x)))
xtable(as.data.frame(sort(recipients, decreasing=TRUE)[1:10]))

df_enron = df[df$from %in% df$to,]
# Top 10 Email Senders (emails to and from users whose folders we have):
senders_enron = tapply(df_enron$message_id, INDEX = df_enron$from,FUN=function(x) length(unique(x)))
xtable(as.data.frame(sort(senders_enron, decreasing=TRUE)[1:10]))
# Top 10 Email Recipients (emails within Enron):
recipients_enron = tapply(df_enron$message_id, INDEX = df_enron$to,FUN=function(x) length(unique(x)))
xtable(as.data.frame(sort(recipients_enron, decreasing=TRUE)[1:10]))

# Plot a figure for sending emails
df_senders = data.frame(senders_enron)
df_senders_plot = ggplot(data=df_senders, aes(df_senders$senders_enron)) + 
  geom_histogram() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Emails Sent per User") +
  xlab("# of Emails Sent") +
  ylab("# of Users")

df_senders_all = data.frame(senders)
df_senders_all_plot = ggplot(data=df_senders_all, aes(df_senders_all$senders)) + 
  geom_histogram() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="All Emails Sent per User") +
  xlab("# of Emails Sent") +
  ylab("# of Users")

# Plot a figure for receiving emails
df_recipients = data.frame(recipients_enron)
df_recipients_plot = ggplot(data=df_recipients, aes(df_recipients$recipients_enron)) + 
  geom_histogram() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Emails Received per User") +
  xlab("# of Emails Received") +
  ylab("# of Users")

df_recipients_all = data.frame(recipients)
df_recipients_all_plot = ggplot(data=df_recipients_all, aes(df_recipients_all$recipients)) + 
  geom_histogram() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="All Emails Received per User") +
  xlab("# of Emails Received") +
  ylab("# of Users")

(df_senders_plot | df_senders_all_plot) / (df_recipients_plot | df_recipients_all_plot)
```

3. Plot another figure to show the interaction between people in this company. You need first get the unique users in this company, and then find out who sent who how many emails. For example, for two people named as A and B, get the total number of emails that A sent to B and the total number of emails that B sent to A. Let's say there are 150 people in this company, you will get a matrix of 150*150. Let the diagonal of this matrix being 0s (since we don't care emails that people sent to himself).  After alphabet sorting all people in the company, you assign each people's name to the column and rows names. 

For the email count matrix, fill the element in (a-th row,b-th column) as the total number of emails the a-th person sent to the b-th person, and then plot this matrix.
    
```{r}
grouped_data <- aggregate(df_enron, by=list(df_enron$from, df_enron$to), FUN=length)

# Get Matrix
pivoted <- grouped_data[,c("Group.1","Group.2","message_id")] %>% 
  pivot_wider(names_from = "Group.2", values_from = "message_id")
pivoted <- pivoted[order(pivoted[,1]),]
pivoted[is.na(pivoted)] <- 0
pivoted <- pivoted[,-1]
emails_matrix <- data.matrix(pivoted)

# Create Plot
grouped_data = grouped_data[order(grouped_data[,1], grouped_data[,2]),]
ggplot(grouped_data, aes(x=Group.1, y=Group.2, fill=log(message_id))) +  #131x131
  geom_tile() +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x=element_blank(),
        axis.text.y=element_blank()) +
  labs(title=paste("Number of Emails Sent To and From each User")) +
  scale_fill_gradient(low = "#FDFDFD", high = "#151CA1",guide=FALSE) +
  xlab("From (alphabetically)") +
  ylab("To (alphabetically)")
```

4. Other interesting plots to show the data or some information in the data to your classmates. 

```{r}
# Number of emails over time
ggplot(df, aes(x=format(email_date, "%w"))) + 
  geom_bar() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title=paste("Emails Sent by Day of the Week")) +
  scale_fill_viridis(guide=FALSE) +
  xlab("Day of the Week") +
  ylab("# of Emails Sent") +
  scale_x_discrete(labels=c("0"="Sun","1"="Mon","2"="Tue","3"="Wed","4"="Thu","5"="Fri","6"="Sat"))

# full emails
for(year in c("1999","2000","2001","2002")){
  assign(paste0("p",year),
         ggplot(df[format(df$email_date,"%Y")==year,],
                aes(x=format(email_date, "%V"),  # colored for Quarters
                    fill=ceiling(as.numeric(format(email_date, "%V"))/13) %% 2)
                ) + 
    geom_bar() +
    theme(plot.title = element_text(hjust = 0.5)) +
    labs(title=paste("Emails per Week of",year)) +
    scale_fill_gradient(low = "#454545", high = "#7090B1",guide=FALSE) +
    xlab("Week Number") +
    ylab("# of Emails Sent") +
    scale_x_discrete(breaks=as.character(seq(from=10,to=50,by=10)))
  )
}
(p1999 | p2000) / (p2001 | p2002)

# subset of emails
for(year in c("1999","2000","2001","2002")){
  assign(paste0("p_enron",year),
         ggplot(df_enron[format(df_enron$email_date,"%Y")==year,],
                aes(x=format(email_date, "%V"),  # colored for Quarters
                    fill=ceiling(as.numeric(format(email_date, "%V"))/13) %% 2)
                ) + 
    geom_bar() +
    theme(plot.title = element_text(hjust = 0.5)) +
    labs(title=paste("Emails per Week of",year)) +
    scale_fill_gradient(low = "#454545", high = "#7090B1",guide=FALSE) +
    xlab("Week Number") +
    ylab("# of Emails Sent") +
    scale_x_discrete(breaks=as.character(seq(from=10,to=50,by=10)))
  )
}
(p_enron1999 | p_enron2000) / (p_enron2001 | p_enron2002)
```

### Distinct and Total Emails
```{r}
# Distinct and Total Emails
distinct_emails <- unique(df_enron[,c(1,4)])
distinct_emails <-aggregate(distinct_emails,by=list(distinct_emails$from), FUN=length)
total_emails <- aggregate(df_enron,by=list(df_enron$from), FUN=length)
user_emails <- merge(x=distinct_emails, y=total_emails, by.x="Group.1", by.y="Group.1")
ggplot(user_emails, aes(x=from.x, y=from.y)) +
  geom_point() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Distinct Emails vs Total Emails") +
  xlab("Distinct Emails") +
  ylab("Total Emails")

ggplot(user_emails, aes(from.y/from.x)) +
  geom_histogram() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Histogram of Average Recipients per Email") +
  xlab("Recipients/Email") +
  ylab("# of Users")

ggplot(user_emails, aes(x=from.y/from.x, y=from.y)) +
  geom_point() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Audience Size vs Emails Sent, by User") +
  xlab("Recipients per Email") +
  ylab("Total Emails")

mean(user_emails$from.y/user_emails$from.x)
median(user_emails$from.y/user_emails$from.x)

distinct_emails_df <- unique(df[,c(1,4)])
distinct_emails_df <-aggregate(distinct_emails_df,by=list(distinct_emails_df$from), FUN=length)
total_emails_df <- aggregate(df,by=list(df$from), FUN=length)
user_emails_df <- merge(x=distinct_emails_df, y=total_emails_df, by.x="Group.1", by.y="Group.1")
ggplot(user_emails_df, aes(x=from.x, y=from.y)) +
  geom_point() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title="Distinct Emails vs Total Emails") +
  xlab("Distinct Emails") +
  ylab("Total Emails")
```

### Subject lines
```{r}
setwd(data_location)
options(warn = -1)

emails.inbox.files <-list.files("maildir/", full.names = T, recursive = T)
print(length(emails.inbox.files))

subjects <- lapply(c(emails.inbox.files), function(x){
  matches <- str_match(readLines(x, warn = F),pattern="^Subject: (R[eE]: )*(.*)$")
  matches <- matches[!is.na(matches[,1]),2:3]
  if(is.null(dim(matches))){
    return(matches)
  }
  return(matches[1,])
})
df_subj <- do.call("rbind",subjects)
subj = df_subj[!duplicated(df_subj),]
# write.csv(df_subj, "all_subjects.csv", row.names=FALSE)
# write.csv(subj, "unique_subjects.csv", row.names=FALSE)
```

```{r}
subj_string = paste(subj[,2], collapse=" ")
subj_string = strsplit(tolower(subj_string), split="[[:space:]]|[[:punct:]]")
subj_string = subj_string[[1]][subj_string[[1]] != ""]

subj_wordtab = table(subj_string)
subj_wordtab_sorted = sort(subj_wordtab, decreasing=TRUE)

subj_string[1:10]  # first 10 words
length(subj_string)  # How many words?
subj_string[order(nchar(subj_string), subj_string, decreasing=TRUE)[1:7]]  # 5 longest words
xtable(as.data.frame(head(subj_wordtab_sorted, 30))) # 30 most common words

nw = length(subj_wordtab_sorted)
plot(1:nw, as.numeric(subj_wordtab_sorted), type="l",xlab="Rank", 
     ylab="Frequency")
#curve(8000*(1/x)^0.6, from=1, to=nw, col="red", add=TRUE)
```

5. Now you want to some interesting data analysis. Assuming that the matrix name you built at step 3 is called `matrix.email.number.stat`, now get a new matrix named `network.email.communication`.

`network.email.communication` can be considered as a social network data, indicating how often two staffs in this company communicating with each other. Let's treat this data as a network and perform network analysis.  Each employee is a node in the network. Try to teach yourself the iGraph package, which is a powerful tool to analyze networks. Try to use functions in the iGraph to visualize the network data, perform community detection and other network data analyses. Note, a community is a group of nodes that are more connected with each other than with any other node.

The graph will you a lot about the group of employees in the Enron corpus and how they relate to each other. Each of the communities represents a tightly connected group of employees that mainly e-mail each other.  Explain your results in the report. 
    
```{r,eval=TRUE}
# Create a graph
network.email.communication = emails_matrix + t(emails_matrix)
email_graph <- graph_from_adjacency_matrix(network.email.communication, 
                                           mode="upper", diag=FALSE, weighted=TRUE)

# Community detection: a community is a group of nodes that are more connected
cluster = cluster_fast_greedy(email_graph)
modularity(cluster)
sizes(cluster)  # sizes of communities
coords3 = layout_nicely(email_graph)
plot(email_graph, vertex.color=membership(cluster), layout=coords3,vertex.label=NA,
     edge.weight=2, edge.width=log(E(email_graph)$weight+1),  # log needed to balance weights
     vertex.size=10)
plot_dendrogram(cluster,xlab=NA)
```

```{r}
# Network over time
get_matrix <- function(dataset){
  pivoted <- dataset %>% 
    pivot_wider(names_from = "Group.2", values_from = "message_id")
  pivoted <- pivoted[order(pivoted[,1]),]
  pivoted[is.na(pivoted)] <- "0"
  pivoted <- pivoted[,-1]
  pivoted <- pivoted[,order(names(pivoted))]
  pivoted <- data.matrix(pivoted)-1  #converting to matrix adds one for some reason
  return(pivoted)
}

for(year in c("1999","2000","2001","2002")){
  year_data <- df_enron[format(df_enron$email_date,"%Y")==year,]
  year_data <- aggregate(year_data,by=list(year_data$from, year_data$to), FUN=length)
  year_data <- year_data[,c("Group.1","Group.2","message_id")]
  # Ensure matrices are square
  add_to_group_2 = setdiff(year_data$Group.1,year_data$Group.2)
  add_to_group_1 = setdiff(year_data$Group.2,year_data$Group.1)
  for(n in add_to_group_2){
    year_data <- rbind(year_data, c(add_to_group_2[1], n, "0"))
  }
  for(n in add_to_group_1){
    year_data <- rbind(year_data, c(n, add_to_group_1[1], "0"))
  }
  assign(paste0("g",year),get_matrix(year_data))
}

network1999 = g1999 + t(g1999)
email_1999 <- graph_from_adjacency_matrix(network1999,mode="upper",diag=FALSE,weighted=TRUE)
cluster1999 = cluster_fast_greedy(email_1999)
modularity(cluster1999)
sizes(cluster1999)
coords3 = layout_nicely(email_1999)
plot(email_1999, vertex.color=membership(cluster1999), layout=coords3,edge.weight=2,
     edge.width=E(email_1999)$weight,vertex.label=NA)

network2000 = g2000 + t(g2000)
email_2000 <- graph_from_adjacency_matrix(network2000,mode="upper",diag=FALSE,weighted=TRUE)
cluster2000 = cluster_fast_greedy(email_2000)
modularity(cluster2000)
sizes(cluster2000)
coords3 = layout_nicely(email_2000)
plot(email_2000, vertex.color=membership(cluster2000), layout=coords3,vertex.label=NA,
     edge.weight=2, edge.width=E(email_2000)$weight,vertex.size=10)

network2001 = g2001 + t(g2001)
email_2001 <- graph_from_adjacency_matrix(network2001,mode="upper",diag=FALSE,weighted=TRUE)
cluster2001 = cluster_fast_greedy(email_2001)
modularity(cluster2001)
sizes(cluster2001)
coords3 = layout_nicely(email_2001)
plot(email_2001, vertex.color=membership(cluster2001), layout=coords3,vertex.label=NA,
     edge.weight=2, edge.width=E(email_2001)$weight,vertex.size=10)

network2002 = g2002 + t(g2002)
email_2002 <- graph_from_adjacency_matrix(network2002,mode="upper",diag=FALSE,weighted=TRUE)
cluster2002 = cluster_fast_greedy(email_2002)
modularity(cluster2002)
sizes(cluster2002)
coords3 = layout_nicely(email_2002)
plot(email_2002, vertex.color=membership(cluster2002), layout=coords3,vertex.label=NA,
     edge.weight=2, edge.width=E(email_2002)$weight,vertex.size=10)
```   


Evaluation
===

Your final score will depend on two components: 1. your report and 2. your R script. Your report should tell a complete and interesting story (with informative figures/data visualization) about the dataset. Your script should be well organized using comments, functions, for loops and so on. 


